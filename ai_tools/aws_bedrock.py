"""
Created by Analitika at 04/12/2024
contact@analitika.fr
https://docs.aws.amazon.com/nova/latest/userguide/getting-started-api.html
https://docs.aws.amazon.com/nova/latest/userguide/image-generation.html
"""
import base64
import io
import json
import warnings

# External imports
# import tiktoken
import boto3
from botocore.config import Config
from botocore.exceptions import ClientError
from loguru import logger

# Internal imports
from config import settings


class ImageError(Exception):
    "Custom exception for errors returned by Amazon Nova Canvas"

    def __init__(self, message: str) -> None:
        self.message = message


class BedrockClient:
    def __init__(self, region_name: str = "us-east-1") -> None:
        """
        Initialize Bedrock client.

        Args:
            region_name (str): AWS region name (default: us-east-1)
        """
        self.client = boto3.Session(
            region_name=region_name,
            aws_access_key_id=settings.AWS_BR_ACCESS_KEY_ID,
            aws_secret_access_key=settings.AWS_BR_SECRET_ACCESS_KEY,
        ).client("bedrock-runtime", settings=Config(read_timeout=300))

    def generate_text(
        self, prompt, model_id="anthropic.claude-v2", max_tokens=1000, temperature=0.7
    ):
        """
        Generate text completion using AWS Bedrock.

        Args:
            prompt (str): Input text prompt
            model_id (str): Bedrock model ID to use
            max_tokens (int): Maximum number of tokens to generate
            temperature (float): Sampling temperature (0.0 to 1.0)

        Returns:
            str: Generated text completion

        Raises:
            ClientError: If API call fails
            Exception: For other errors
        """
        try:
            # Prepare the request body based on the model
            if "anthropic" in model_id:
                body = {
                    "prompt": f"\n\nHuman: {prompt}\n\nAssistant:",
                    "max_tokens_to_sample": max_tokens,
                    "temperature": temperature,
                }
            elif "nova" in model_id:
                # Nova models use the converse endpoint with a different format
                body = {
                    "messages": [
                        # {"role": "assistant", "content": [{"text": "You are a helpful assistant."}]},
                        {"role": "user", "content": [{"text": prompt}]},
                    ],
                    "inferenceConfig": {
                        "maxTokens": max_tokens,
                        "temperature": temperature,
                    },
                }

                # Use converse endpoint for Nova models
                response = self.client.converse(modelId=model_id, **body)

                # Extract text from Nova's specific response format
                return response["output"]["message"]["content"][0]["text"]
            elif "titan-text" in model_id:
                body = {
                    "inputText": prompt,
                    "textGenerationConfig": {
                        "maxTokenCount": max_tokens,
                        "temperature": temperature,
                        "topP": 1,
                        "stopSequences": [],
                    },
                }
            else:
                raise ValueError(f"Unsupported model: {model_id}")

            # Make the API call
            response = self.client.invoke_model(modelId=model_id, body=json.dumps(body))

            # Parse the response based on the model
            response_body = json.loads(response["body"].read())
            if "anthropic" in model_id:
                return response_body.get("completion", "").strip()
            elif "nova" in model_id:
                return response_body.get("output", "").strip()
            elif "titan-text" in model_id:
                return response_body.get("results", [{}])[0].get("outputText", "").strip()

        except ClientError as e:
            print(f"AWS API error: {e}")
            raise
        except Exception as e:
            print(f"Error generating completion: {e}")
            raise

    def generate_image(self, model_id="amazon.nova-canvas-v1:0", body=None) -> io.BytesIO:
        """
        Generate an image using Amazon Nova Canvas model on demand.
        Args:
            model_id (str): The model ID to use.
            body (str) : The request body to use.
        Returns:
            image_bytes (bytes): The image generated by the model.
        """

        if body is None:
            raise ValueError("Body must be provided for image generation")

        logger.info(f"Generating image with Amazon Nova Canvas: {model_id}")

        accept = "application/json"
        content_type = "application/json"

        try:
            response = self.client.invoke_model(
                body=body, modelId=model_id, accept=accept, contentType=content_type
            )
            response_body = json.loads(response.get("body").read())
            base64_image = response_body.get("images")[0]
            base64_bytes = base64_image.encode("ascii")
            image_bytes = base64.b64decode(base64_bytes)
            image = io.BytesIO(image_bytes)
            # image = Image.open(io.BytesIO(image_bytes))

            finish_reason = response_body.get("error")

            if finish_reason is not None:
                raise ImageError(f"Image generation error. Error is {finish_reason}")

            logger.info(
                "Successfully generated image with Amazon Nova Canvas  model %s",
                model_id,
            )

            return image

        except ClientError as err:
            message = err.response["Error"]["Message"]
            logger.error("A client error occurred:", message)
        except ImageError as err:
            logger.error(err.message)

    @classmethod
    def configure_text_to_image_params(
        cls,
        text: str,
        negative_text: str = None,
        num_images: int = 1,
        height: int = 1024,
        width: int = 1024,
        cfg_scale: float = 8.0,
        seed: int = 42,
        task_type: str = "TEXT_IMAGE",  # Added to differentiate between generation and editing
    ) -> dict:
        """
        Creates a configuration dictionary for text-to-image generation using Amazon Bedrock's image generation API.

        This function validates and structures parameters for image generation, ensuring they meet API requirements
        for resolution, text length, and other constraints. It supports both positive and negative text prompts,
        along with various image generation settings.

        Parameters
        ----------
        text : str
            The primary text prompt describing what should appear in the generated image.
            Must be 1024 characters or less.

        negative_text : str, optional
            Text describing elements to exclude from the generated image. Should be stated in positive terms
            (e.g., use "mirrors" instead of "no mirrors"). Must be 512 characters or less.

        num_images : int, optional
            Number of images to generate. Must be between 1 and 5 inclusive.
            Defaults to 1.

        height : int, optional
            Height of the output image in pixels. Must be one of the permitted resolutions.
            Defaults to 1408. See Notes section for valid resolution pairs.

        width : int, optional
            Width of the output image in pixels. Must be one of the permitted resolutions.
            Defaults to 1408. See Notes section for valid resolution pairs.

        cfg_scale : float, optional
            Controls how closely the generated image follows the prompt. Range: 1.1 to 10.0.
            Lower values allow more creative freedom, higher values stick closer to the prompt.
            Defaults to 8.0.

        seed : int, optional
            Random seed for reproducible generation. Range: 0 to 2,147,483,647.
            Using the same seed with identical parameters will produce similar results.
            Defaults to 42.

        task_type : str, optional
            Differentiate between generation and editing
            Defaults to TEXT_IMAGE.

        Returns
        -------
        dict
            A properly formatted configuration dictionary compatible with the Amazon Bedrock
            image generation API.

        Notes
        -----
        Valid width x height resolution pairs include:
        (2048, 2048),  # 1:1
        (2816, 1536),  # ~1.83:1
        (1536, 2816),  # ~1:1.83
        (2048, 1536),  # 4:3
        (1536, 2048),  # 3:4
        (2560, 1536),  # 5:3
        (1536, 2560),  # 3:5

        Examples
        --------
        >>> config = configure_text_to_image_params(
        ...     text="A serene mountain landscape at sunset",
        ...     negative_text="buildings people cars",
        ...     width=1024,
        ...     height=1024,
        ...     cfg_scale=7.5
        ... )

        Raises
        ------
        ValueError
            If any parameters are outside their valid ranges or if text prompts exceed 512 characters.
        """
        # Calculate total pixels and aspect ratio
        total_pixels = width * height
        aspect_ratio = width / height

        # Validation for image dimensions based on task type
        if task_type == "TEXT_IMAGE":  # Generation tasks
            if total_pixels > 4190000:  # 4.19 million pixels
                raise ValueError("Total pixel count exceeds 4.19 million pixels limit")

            # Common generation resolutions (you can add more as needed) "1024x1024", "1792x1024", "1024x1792"
            valid_resolutions = {
                (1024, 1024),  # 1:1
                (1792, 1024),  # ~1.75:1
                (1024, 1792),  # ~1:1.75
                (2048, 2048),  # 1:1
                (2816, 1536),  # ~1.83:1
                (1536, 2816),  # ~1:1.83
                (2048, 1536),  # 4:3
                (1536, 2048),  # 3:4
                (2560, 1536),  # 5:3
                (1536, 2560),  # 3:5
            }

            if (width, height) not in valid_resolutions:
                warnings.warn(
                    f"Invalid resolution for generation task. Must be one of {valid_resolutions}",
                    stacklevel=2,
                )

        # Check maximum dimension
        max_dimension = max(width, height)
        if max_dimension > 4096:
            raise ValueError("Longest side cannot exceed 4096 pixels for editing tasks")

        # Check aspect ratio (between 1:4 and 4:1)
        if aspect_ratio < 0.25 or aspect_ratio > 4.0:
            raise ValueError("Aspect ratio must be between 1:4 and 4:1 for editing tasks")

        # Check total pixels
        if total_pixels > 4190000:
            raise ValueError("Total pixel count exceeds 4.19 million pixels limit")

        # Initialize the tokenizer - using cl100k_base as an example, adjust as needed
        # tokenizer = tiktoken.get_encoding("cl100k_base")

        # Count tokens for the main text prompt
        # text_tokens = tokenizer.encode(text)
        if len(text) > 1024:
            raise ValueError(f"Text prompt exceeds 1024 characters (current: {len(text)})")

        # negative_text_tokens = tokenizer.encode(text)
        if negative_text is not None and len(negative_text) > 512:
            raise ValueError(
                f"Negative text exceeds 512 characters (current: {len(negative_text)})"
            )

        if num_images != 1:
            # if num_images < 1 or num_images > 5:
            raise ValueError("Number of images must be 1 (nova-canvas model)")

        if cfg_scale < 1.1 or cfg_scale > 10.0:
            raise ValueError("CFG scale must be between 1.1 and 10.0")

        if seed < 0 or seed > 2147483647:
            raise ValueError("Seed must be between 0 and 2,147,483,647")

        # Construct the configuration dictionary
        config = {
            "taskType": task_type,
            "textToImageParams": {"text": text},
            "imageGenerationConfig": {
                "numberOfImages": num_images,
                "height": height,
                "width": width,
                "cfgScale": cfg_scale,
                "seed": seed,
            },
        }

        # Add optional negative text if provided
        if negative_text:
            config["textToImageParams"]["negativeText"] = negative_text

        return config


def test_text_generation() -> str:
    # Initialize the completion client
    completion = BedrockClient(region_name="us-east-1")

    # Example prompt
    prompt = "Write a short story about a robot learning to paint."

    try:
        # Generate completion
        result = completion.generate_text(
            prompt=prompt,
            model_id="amazon.nova-lite-v1:0",
            # model_id="amazon.nova-micro-v1:0",
            # model_id="amazon.titan-text-lite-v1",
            # max_tokens=500,
            # temperature=0.7
        )
        logger.info("Generated text:")
        logger.info(result)

    except Exception as e:
        logger.critical(f"Failed to generate completion: {e}")


def test_image_generation() -> io.BytesIO:
    completion = BedrockClient(region_name="us-east-1")
    model_id = "amazon.nova-canvas-v1:0"
    prompt = """A photograph of a cup of coffee from the side."""

    config = BedrockClient.configure_text_to_image_params(
        text=prompt[:1022],
        negative_text="buildings people cars",
        width=1024,
        height=1024,
        cfg_scale=8.0,
        seed=42,
    )

    # body = json.dumps(
    #     {
    #         "taskType": "TEXT_IMAGE",
    #         "textToImageParams": {
    #             "text": prompt,
    #             "negative_text": "buildings people cars",
    #         },
    #         "imageGenerationConfig": {
    #             "numberOfImages": 1,
    #             "height": 1024,
    #             "width": 1024,
    #             "cfgScale": 8.0,
    #             "seed": 0,
    #         },
    #     }
    # )

    config_body = json.dumps(config)

    image = completion.generate_image(model_id=model_id, body=config_body)

    # Save the image to a local file
    # image.save('output_image.jpg')

    # from wordpress_api import Post, Media, Category, Tag
    # from config import WP_URL, WP_USERNAME, WP_ACCESSKEY
    # from wordpress_api import WordPressAPI
    #
    # api = WordPressAPI(WP_URL, WP_USERNAME, WP_ACCESSKEY)
    # media_data = Media(
    #     title="title",
    #     alt_text="alt_text",
    #     caption="caption",
    #     description="title",
    #     status="publish",
    #     meta={},
    # )
    # new_media = api.create_media(
    #     image, media=media_data
    # )
    logger.info(f"Finished generating image with Amazon Nova Canvas  model {model_id}.")
    return image


# Example usage
if __name__ == "__main__":
    # test_text_generation()
    test_image_generation()
